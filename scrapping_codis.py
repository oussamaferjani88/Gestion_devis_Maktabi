import imaplib
import email
import unicodedata
from bs4 import BeautifulSoup
import pandas as pd
from io import StringIO
import re
import unidecode    
# ========================
# 0 Utilitaires
# ========================
COLUMN_MAP = {
    'REF': [
        'ref', 'r√©f√©rence', 'reference', 'r√©ference', 'code', 'sku',
        'codearticle', 'refprod', 'refproduit', 'productcode', 'product_ref',
        'refproduit', 'referenceproduit', 'ref produit'
    ],

    'FAMILLE': [
        'famille', 'categorie', 'cat√©gorie', 'category', 'family',
        'productfamily', 'categorieproduit', 'familleproduit', 'fam',
        'cat', 'groupe', 'designation', 'nom', 'nomproduit', 'nom_prod',
        'designationproduit', 'libelle', 'libell√©'
    ],

    'DESCRIPTION': [
        'description', 'designation', 'd√©signation', 'descr', 'desc',
        'titre', 'productname', 'designationproduit', 'libelle', 'libell√©'
    ],

    'Prix HT': [
        'prix', 'prixht', 'prix_unitaire', 'prixunitaire', 'prixunitaireht',
        'price', 'unitprice', 'unit_price', 'prixunitairehtva', 'puht',
        'prixhtva', 'prixht'
    ],

    'Disponibilit√©': [
        'disponibilite', 'disponibilit√©', 'stock',  'availability',
        'etat', 'etatstock', 'stockstatus', 'status', 'availabilitystatus'
    ]
}
def normalize_text(text):
    """
    Normalize text to compare header candidates.
    - Lowercase
    - Remove accents
    - Remove spaces
    - Remove punctuation
    """
    if not isinstance(text, str):
        return ""
    text = unidecode.unidecode(text).lower()
    text = re.sub(r'\s+', '', text)
    text = re.sub(r'[^a-z0-9]', '', text)
    return text.strip()
# Create a set of all normalized header variants from COLUMN_MAP
COLUMN_KEYWORDS = set()
for variants in COLUMN_MAP.values():
    COLUMN_KEYWORDS.update([normalize_text(v) for v in variants])

def format_codis_price_clean(df):
    def transform(val):
        if pd.isna(val):
            return pd.NA
        try:
            # Supprimer tous les caract√®res sauf chiffres, points ou virgules
            val = re.sub(r'[^0-9,\.]', '', str(val))

            # Normaliser virgule en point
            val = val.replace(',', '.')

            # Convertir en float, puis prendre partie enti√®re
            num = float(val)
            return str(int(num)) + ',000'

        except:
            return pd.NA

    df['Prix HT'] = df['Prix HT'].apply(transform)
    return df


# ========================
# 1Ô∏è‚É£ Connexion IMAP
# ========================
IMAP_SERVER = 'imap.gmail.com'
EMAIL_ACCOUNT = 'hjaiejnessim@gmail.com'
EMAIL_PASSWORD = 'chpr cjbp uuyr kbic'

mail = imaplib.IMAP4_SSL(IMAP_SERVER)
mail.login(EMAIL_ACCOUNT, EMAIL_PASSWORD)
mail.select('INBOX')

# ========================
# 2Ô∏è‚É£ Recherche d'emails sp√©cifiques
# ========================
senders_raw = ["maktabi2013@gmail.com", "Hanene.BOUAZZA@codis.com.tn"]
subjects_raw = ["Codis", "Lenovo"]

senders_normalized = [normalize_text(s) for s in senders_raw]
subjects_normalized = [normalize_text(s) for s in subjects_raw]

all_ids = set()

# Recherche par FROM
for sender in senders_raw:
    result, data = mail.search(None, f'FROM "{sender}"')
    ids = set(data[0].split())
    all_ids.update(ids)

# Recherche par SUBJECT
for subj in subjects_raw:
    result, data = mail.search(None, f'SUBJECT "{subj}"')
    ids = set(data[0].split())
    all_ids.update(ids)

email_ids = list(all_ids)


if not email_ids:
    print("‚ùå Aucun email trouv√© avec ce crit√®re.")
    exit()


print("‚úÖ Email trouv√© et charg√©.")

# ========================
# 3Ô∏è‚É£ Extraire le corps HTML
# ========================
df_list = []

for email_idx, email_id in enumerate(email_ids, start=1):
    print(f"\nüì• Processing email {email_idx}/{len(email_ids)} ID: {email_id.decode()}")

    # ========================
    # Fetch this email
    # ========================
    result, msg_data = mail.fetch(email_id, '(RFC822)')
    msg = email.message_from_bytes(msg_data[0][1])

    # ========================
    # Extract HTML content
    # ========================
    html_content = None
    for part in msg.walk():
        if part.get_content_type() == "text/html":
            html_content = part.get_payload(decode=True).decode(errors='ignore')
            break

    if not html_content:
        print("‚ùå Aucun contenu HTML trouv√© dans cet email.")
        continue

    print("‚úÖ Contenu HTML extrait.")

    # ========================
    # Parse all tables in this email
    # ========================
    soup = BeautifulSoup(html_content, 'html.parser')
    tables = soup.find_all('table')

    if not tables:
        print("‚ùå Aucun tableau trouv√© dans cet email.")
        continue

    print(f"‚úÖ {len(tables)} tableau(x) trouv√©(s) dans cet email.")

    for idx, table in enumerate(tables):
        try:
            html_str = str(table)
            # Always read WITHOUT header
            df_raw = pd.read_html(StringIO(html_str), header=None)[0]

            # Check first row
            first_row = df_raw.iloc[0].astype(str).apply(normalize_text).tolist()
            has_header = any(cell in COLUMN_KEYWORDS for cell in first_row)

            if has_header:
                # ‚úÖ First row is header
                df_raw.columns = df_raw.iloc[0].astype(str).str.strip()
                df_piece = df_raw[1:].reset_index(drop=True)
                print(f"‚úÖ Header detected in first row for table {idx + 1}.")
            else:
                # ‚ùå No header ‚Üí generic columns
                df_raw.columns = [f'COL{i+1}' for i in range(df_raw.shape[1])]
                df_piece = df_raw
                print(f"‚ö†Ô∏è No header detected in first row for table {idx + 1}. Using generic columns.")

            # Clean column names
            df_piece.columns = [str(c).strip() for c in df_piece.columns]
            # Nettoyage des caract√®res invisibles dans les cellules
            # Nettoyage des espaces invisibles unicode (non-breaking spaces, etc.)
            df_piece = df_piece.applymap(
                 lambda x: ''.join(
                    c for c in unicodedata.normalize('NFKC', str(x))
                        if not unicodedata.category(c).startswith('Z')
                 ).strip() if isinstance(x, str) else x
                )
            # Standardize or split wide tables
            if len(df_piece.columns) == 5:
                df_piece.columns = ["REF", "FAMILLE", "DESCRIPTION", "Prix HT", "Disponibilit√©"]
                df_list.append(df_piece)
            elif len(df_piece.columns) == 3:
                df_piece.columns = ["REF", "FAMILLE", "Prix HT"]
                df_list.append(df_piece)
            elif len(df_piece.columns) == 4:
                df_piece.columns = ["REF", "FAMILLE", "DESCRIPTION", "Prix HT"]
                df_list.append(df_piece)
            elif len(df_piece.columns) == 2:
                df_piece.columns = ["REF", "Prix HT"]
                df_list.append(df_piece)
            elif len(df_piece.columns) > 5:
                df_piece = df_piece.dropna(axis=1, how='all')
                num_all_columns = df_piece.shape[1]
                split_index = num_all_columns // 2
                df_left = df_piece.iloc[:, :split_index]
                df_right = df_piece.iloc[:, split_index:]
                df_left.columns = ["REF", "FAMILLE",  "Prix HT"]
                df_right.columns = ["REF", "FAMILLE", "Prix HT"]
                
                df_list.append(df_left)
                df_list.append(df_right)

            print(f"‚úÖ Tableau {idx + 1} extrait et standardis√© ({df_piece.shape[0]} lignes).")

        except Exception as e:
            print(f"‚ö†Ô∏è Erreur sur le tableau {idx + 1} de l'email {email_idx}: {e}")


if not df_list:
    print("‚ùå Aucun tableau valide trouv√© .")
    exit()

df_codis = pd.concat(df_list, ignore_index=True)
df_codis = format_codis_price_clean(df_codis)
df_codis.to_excel('codis_extracted_data.xlsx', index=False)
print(f"‚úÖ Total lignes combin√©es : {len(df_codis)}")

# ========================
# 5Ô∏è‚É£ Nettoyage des donn√©es fournisseur
# ========================

df_codis.columns = [col.strip() for col in df_codis.columns]
df_codis = df_codis.applymap(lambda x: x.strip() if isinstance(x, str) else x)


df_codis['Disponibilit√©'] = df_codis['Disponibilit√©'].str.strip().str.upper()

# ‚úÖ Conserver aussi la colonne FAMILLE
df_codis = df_codis[['REF', 'FAMILLE', 'Prix HT', 'Disponibilit√©']].dropna(subset=['REF'])
df_codis = df_codis.rename(columns={
    'REF': 'reference_mytek',
    'Prix HT': 'prix_codis',
    'Disponibilit√©': 'disponibilite_codis'
})

print("‚úÖ Donn√©es du fournisseur pr√™tes :")
print(df_codis.head())

# ========================
# 6Ô∏è‚É£ Charger le catalogue table.xlsx
# ========================
df_table = pd.read_excel('table.xlsx', sheet_name='Sheet3')
print(f"‚úÖ table.xlsx charg√© ({df_table.shape[0]} lignes).")

# ========================
# 7Ô∏è‚É£ Nettoyer les r√©f√©rences dans table et codis
# ========================
def clean_ref(ref):
    if isinstance(ref, str):
        return re.sub(r'[^A-Za-z0-9]', '', ref).upper()
    return ref

if 'reference_mytek' in df_table.columns:
    df_table['reference_mytek'] = df_table['reference_mytek'].apply(clean_ref)
if 'reference_tunisianet' in df_table.columns:
    df_table['reference_tunisianet'] = df_table['reference_tunisianet'].apply(clean_ref)
df_codis['reference_mytek'] = df_codis['reference_mytek'].apply(clean_ref)

# ========================
# 8Ô∏è‚É£ Fusion en deux √©tapes : mytek puis fallback tunisianet
# ========================
merged_mytek = df_table.merge(
    df_codis,
    left_on='reference_mytek',
    right_on='reference_mytek',
    how='left',
    suffixes=('', '_codis')
)

print(f"‚úÖ Merge sur reference_mytek termin√© ({merged_mytek.shape[0]} lignes).")
needs_fallback = merged_mytek[merged_mytek['prix_codis'].isna()]
print(f"‚úÖ Lignes sans prix_codis apr√®s 1er merge : {needs_fallback.shape[0]}")

if not needs_fallback.empty:
    fallback_merge = needs_fallback.drop(columns=['prix_codis', 'disponibilite_codis']).merge(
        df_codis,
        left_on='reference_tunisianet',
        right_on='reference_mytek',
        how='left'
    )
    merged_mytek.update(fallback_merge[['prix_codis', 'disponibilite_codis']])
    print("‚úÖ Fallback merge sur reference_tunisianet termin√© et valeurs compl√©t√©es.")
else:
    print("‚úÖ Pas besoin de fallback, tous les prix trouv√©s sur reference_mytek.")

# ========================
# 9Ô∏è‚É£ Comparer avec anciens prix et √©viter √©crasement inutile
# ========================
merged_mytek = merged_mytek.reset_index(drop=True)
df_table = df_table.reset_index(drop=True)

for col in ['prix_codis', 'disponibilite_codis']:
    if col in df_table.columns:
        merged_mytek[col] = merged_mytek.apply(
            lambda row: row[col] if pd.notnull(row[col]) and (row[col] != df_table.loc[row.name, col]) else df_table.loc[row.name, col],
            axis=1
        )
        changes = (merged_mytek[col] != df_table[col]) & merged_mytek[col].notnull()
        print(f"‚úÖ {changes.sum()} changement(s) d√©tect√©(s) pour la colonne {col}")

# ========================
# üîü Ajouter les nouveaux produits Codis non pr√©sents dans le catalogue
# ========================
refs_catalogue_mytek = df_table['reference_mytek'].dropna().unique()
refs_catalogue_tunisianet = df_table['reference_tunisianet'].dropna().unique()
refs_connues = set(refs_catalogue_mytek).union(set(refs_catalogue_tunisianet))
refs_codis = set(df_codis['reference_mytek'].dropna().unique())

nouveaux_refs = refs_codis - refs_connues
print(f"‚úÖ Nouveaux produits d√©tect√©s : {len(nouveaux_refs)}")

if nouveaux_refs:
    nouveaux_produits = df_codis[df_codis['reference_mytek'].isin(nouveaux_refs)].copy()
    nouveaux_produits['nom'] = nouveaux_produits['FAMILLE']
    nouveaux_produits['reference_officielle'] = nouveaux_produits['reference_mytek']
        # ‚úÖ Assigner automatiquement une sous_categorie_id
    def trouver_sous_categorie(famille):
        if not isinstance(famille, str) or famille.strip() == "":
            return -1
        matches = df_table[df_table['nom'].str.contains(famille, case=False, na=False)]
        if not matches.empty:
            return matches['sous_categorie_id'].mode().iloc[0]
        else:
            return -1

    nouveaux_produits['sous_categorie_id'] = nouveaux_produits['FAMILLE'].apply(trouver_sous_categorie)


    # ‚úÖ G√©n√©rer des IDs uniques pour les nouveaux produits
    if 'id' in df_table.columns:
        max_id = df_table['id'].max()
        if pd.isna(max_id):
            max_id = 0
        nouveaux_ids = range(int(max_id) + 1, int(max_id) + 1 + len(nouveaux_produits))
        nouveaux_produits['id'] = list(nouveaux_ids)
        print(f"‚úÖ IDs attribu√©s aux nouveaux produits : {list(nouveaux_ids)}")

    # ‚úÖ Ajouter colonnes manquantes avec valeurs par d√©faut
    colonnes_base = list(merged_mytek.columns)
    for col in colonnes_base:
        if col not in nouveaux_produits.columns:
            if col == 'sous_categorie_id':
                nouveaux_produits[col] = -1
            else:
                nouveaux_produits[col] = pd.NA

    # ‚úÖ Remettre les colonnes dans le m√™me ordre
    nouveaux_produits = nouveaux_produits[colonnes_base]

    # ‚úÖ Ajouter √† la table
    merged_mytek = pd.concat([merged_mytek, nouveaux_produits], ignore_index=True)
    print(f"‚úÖ {len(nouveaux_refs)} nouveaux produits ajout√©s √† la table avec nom depuis FAMILLE.")


# ‚úÖ Assurer que 'reference_officielle' est plac√© juste apr√®s 'id'
colonnes = list(merged_mytek.columns)
if 'id' in colonnes and 'reference_officielle' in colonnes:
    idx_id = colonnes.index('id')
    colonnes.remove('reference_officielle')
    colonnes = colonnes[:idx_id + 1] + ['reference_officielle'] + colonnes[idx_id + 1:]
    merged_mytek = merged_mytek[colonnes]
    print("‚úÖ Colonne 'reference_officielle' ins√©r√©e apr√®s 'id'.")

# ========================
# 11Ô∏è‚É£ R√©organisation des colonnes pour Excel
# ========================
# === Nettoyage final avant export ===
if 'FAMILLE' in merged_mytek.columns:
    merged_mytek.drop(columns=['FAMILLE'], inplace=True)

colonnes_prix = ['prix_codis', 'mytek_avant_remise', 'mytek_apres_remise', 'tunisianet_avant_remise', 'tunisianet_apres_remise']

def ligne_sans_prix(row):
    return all(pd.isna(row.get(c)) or str(row[c]).strip() == '' for c in colonnes_prix)

merged_mytek = merged_mytek[~merged_mytek.apply(ligne_sans_prix, axis=1)].reset_index(drop=True)

colonnes = list(merged_mytek.columns)

if 'nom' not in colonnes:
    print("‚ùå La colonne 'nom' est absente de table.xlsx !")
    exit()

idx_nom_produit = colonnes.index('nom')
colonnes_sans_new = [c for c in colonnes if c not in ['prix_codis', 'disponibilite_codis']]
nouvel_ordre = (
    colonnes_sans_new[:idx_nom_produit + 1]
    + ['prix_codis', 'disponibilite_codis']
    + colonnes_sans_new[idx_nom_produit + 1:]
)


df_final = merged_mytek[nouvel_ordre]

# ========================
# 12Ô∏è‚É£ Sauvegarde Excel
# ========================
df_final.to_excel('table_modifiee.xlsx', index=False)
print("‚úÖ Fichier final g√©n√©r√© : table_modifiee.xlsx")
